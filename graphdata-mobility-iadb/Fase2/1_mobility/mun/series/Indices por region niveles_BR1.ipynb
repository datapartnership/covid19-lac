{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/enum.py\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "print(enum.__file__)  \n",
    "# standard library location should be something like \n",
    "# /usr/local/lib/python3.6/enum.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping enum34 as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip uninstall -y enum34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: openpyxl~=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (3.0.6)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: pymysql<1.1.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.0.2)\n",
      "Requirement already satisfied: pandas<1.3.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.1.5)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.15.49 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.20.87)\n",
      "Requirement already satisfied: pg8000<1.20.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.12.49 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.17.87)\n",
      "Requirement already satisfied: pyarrow<4.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (4.0.0)\n",
      "Requirement already satisfied: redshift-connector~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (2.0.881)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.12.49->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.0.0,>=1.12.49->awswrangler) (0.4.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.15.49->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.0.0,>=1.15.49->awswrangler) (1.26.5)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.3.0,>=1.1.0->awswrangler) (2021.1)\n",
      "Requirement already satisfied: scramp==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pg8000<1.20.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: asn1crypto==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scramp==1.4.0->pg8000<1.20.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.15.49->awswrangler) (1.15.0)\n",
      "Requirement already satisfied: requests<2.25.2,>=2.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (2.25.1)\n",
      "Requirement already satisfied: lxml>=4.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (4.6.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.0->awswrangler) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector~=2.0.0->awswrangler) (2.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.0->awswrangler) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAthena in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.20.87)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (7.0.0)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.17.87)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.5.52->PyAthena) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install PyAthena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectar con pyathena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena.pandas.cursor import PandasCursor\n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "import time\n",
    "# agregar directorio en el cual se almacenan las tablas que se van a consultar\n",
    "directorio = 's3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/athena-results/'\n",
    "# base de datos\n",
    "bd = 'graphdata' # Database in Glue\n",
    "cursor = connect(s3_staging_dir = directorio, region_name = 'us-east-1', schema_name = bd, cursor_class = PandasCursor).cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "import calendar\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaraci√≥n funciones para Impo-Expo s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_csv_on_s3(dataframe, bucket, filename):\n",
    "    \"\"\" Write a dataframe to a CSV on S3 \"\"\"\n",
    "    # Create buffer\n",
    "    csv_buffer = StringIO()\n",
    "    # Write dataframe to buffer\n",
    "    dataframe.to_csv(csv_buffer, sep=\";\" , line_terminator='\\n')\n",
    "    # Create S3 object\n",
    "    s3_resource = boto3.resource(\"s3\")\n",
    "    # Write buffer to S3 object\n",
    "    s3_resource.Object(bucket, filename).put(Body=csv_buffer.getvalue())\n",
    "    print(\"Writing {} records to {}\".format(len(dataframe), filename))\n",
    "    print(\"S3\")\n",
    "    print(dataframe.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_excel_on_s3(dataframe, bucket, filename):\n",
    "    \"\"\" Write a dataframe to a excel on S3 \"\"\"\n",
    "    with io.BytesIO() as output:\n",
    "        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "            dataframe.to_excel(writer,index=False)\n",
    "        data = output.getvalue()\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).put_object(Key=filename, Body=data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe_csv_from_s3(bucket, filename):\n",
    "    client = boto3.client('s3')\n",
    "    bucket_name = bucket\n",
    "    object_key = filename\n",
    "    csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string),sep=\";\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe_excel_from_s3(bucket, filename):\n",
    "    client = boto3.client('s3')\n",
    "    bucket_name = bucket\n",
    "    object_key = filename\n",
    "    obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    data = obj['Body'].read()\n",
    "    df = pd.read_excel(io.BytesIO(data), encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_to_s3(bucket,file_local,file_s3):\n",
    "    s3.Bucket(bucket).upload_file(file_local,file_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importacion de Delta de Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_inicio = '09-01-2020'\n",
    "fecha_final = '09-30-2020'\n",
    "fechas = pd.date_range(fecha_inicio, fecha_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pais = 'BR'\n",
    "nivel_1 = 'id_provincia'\n",
    "nivel_4 = 'cd_geocmi'\n",
    "filtro_variable = \"n_obs\"\n",
    "filtro_num = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computar serie de usuarios homogenea\n",
    "filtro_variable2 = 'n_obs_madrugada'\n",
    "filtro_variable22 = 'n_obs_noche'\n",
    "filtro_num2 = 4\n",
    "#consulta athena\n",
    "tabla_usuarios_distancia =  f'historico_usuarios_regiones_{pais}'   \n",
    "query_filtro = (f''' SELECT caid,count(*) as count_filtro\n",
    "                     FROM {tabla_usuarios_distancia} \n",
    "                     WHERE (({tabla_usuarios_distancia}.{filtro_variable2} + {tabla_usuarios_distancia}.{filtro_variable22})>= {filtro_num2})\n",
    "                     GROUP BY caid\n",
    "                     HAVING count(*)>=30''')\n",
    "df_filtro = cursor.execute(query_filtro).as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91, 67 seg\n",
      "92, 60 seg\n",
      "93, 60 seg\n",
      "94, 62 seg\n",
      "95, 61 seg\n",
      "96, 58 seg\n",
      "97, 56 seg\n",
      "98, 58 seg\n",
      "99, 62 seg\n",
      "910, 61 seg\n",
      "911, 56 seg\n",
      "912, 59 seg\n",
      "913, 43 seg\n",
      "914, 43 seg\n",
      "915, 40 seg\n",
      "916, 32 seg\n",
      "917, 31 seg\n",
      "918, 25 seg\n",
      "919, 29 seg\n",
      "920, 28 seg\n",
      "921, 49 seg\n",
      "922, 62 seg\n",
      "923, 59 seg\n",
      "924, 62 seg\n",
      "925, 59 seg\n",
      "926, 63 seg\n",
      "927, 58 seg\n",
      "928, 61 seg\n",
      "929, 65 seg\n",
      "930, 53 seg\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for fecha in fechas:\n",
    "    time_fecha = time.time()\n",
    "    dia = str(fecha.day)\n",
    "    mes = str(fecha.month)\n",
    "    query_fecha = \"\"\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    tabla_usuarios_distancia =  f'historico_usuarios_regiones_{pais}'   \n",
    "    query_filtro = (f''' SELECT *\n",
    "                         FROM {tabla_usuarios_distancia} \n",
    "                         WHERE ({tabla_usuarios_distancia}.month={mes}\n",
    "                         AND {tabla_usuarios_distancia}.day={dia} \n",
    "                         AND {tabla_usuarios_distancia}.iso_country_code ='{pais}' \n",
    "                         AND {tabla_usuarios_distancia}.{filtro_variable} >= {filtro_num})''')\n",
    "    df = cursor.execute(query_filtro).as_pandas()\n",
    "    df['MasDe1km'] = df['distancia_recorrida'].apply(lambda x: 1 if x>=1 else 0)\n",
    "    \n",
    "    \n",
    "    ##Filtro mas tenue\n",
    "    #nivel 1\n",
    "    df_by_day_1=df.groupby(['month','day',nivel_1]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_1=df_by_day_1.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_1['%MasDe1km'] = df_by_day_1['MasDe1km']/df_by_day_1['n_users']*100  \n",
    "    df_median=df[df['MasDe1km']==1].groupby(['month','day',nivel_1]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_1=df_by_day_1.merge(df_median, how='left',on=['Mes','Dia',nivel_1])\n",
    "    df_by_day_1[nivel_1]=df_by_day_1[nivel_1].astype('int')\n",
    "    df_by_day_1['Mes']=df_by_day_1['Mes'].astype('int')\n",
    "    df_by_day_1['Dia']=df_by_day_1['Dia'].astype('int')\n",
    "    df_by_day_1[\"Dia\"]=df_by_day_1[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_1[\"key4\"]=df_by_day_1['Mes'].astype(str)+ df_by_day_1[\"Dia\"].astype(str)\n",
    "    df_by_day_1['key4']=df_by_day_1['key4'].astype('int')\n",
    "    df_by_day_1['Dia']=df_by_day_1['Dia'].astype('int')    \n",
    "    if (nivel_1==\"id_provincia\"):\n",
    "        df_by_day_1=df_by_day_1.rename(columns={nivel_1:'adm1'})\n",
    "    #if (dia=='1' and mes=='2'):\n",
    "    #    df_final_1=df_by_day_1\n",
    "    #else:\n",
    "    #    df_final_1=df_final_1.append(df_by_day_1)\n",
    "    \n",
    "    \n",
    "    table_uc = f'historico_latlong_{pais}_{codigo_fecha}_nivel1'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_1,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_niveles/Temp_BR/{table_uc}\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #nivel 4   \n",
    "    df_by_day_4=df.groupby(['month','day',nivel_4]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_4=df_by_day_4.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_4['%MasDe1km'] = df_by_day_4['MasDe1km']/df_by_day_4['n_users']*100  \n",
    "    df_median=df[df['MasDe1km']==1].groupby(['month','day',nivel_4]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_4=df_by_day_4.merge(df_median, how='left',on=['Mes','Dia',nivel_4])    \n",
    "    df_by_day_4[nivel_4]=df_by_day_4[nivel_4].astype('int')\n",
    "    df_by_day_4['Mes']=df_by_day_4['Mes'].astype('int')\n",
    "    df_by_day_4['Dia']=df_by_day_4['Dia'].astype('int')\n",
    "    df_by_day_4[\"Dia\"]=df_by_day_4[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_4[\"key4\"]=df_by_day_4['Mes'].astype(str)+ df_by_day_4[\"Dia\"].astype(str)\n",
    "    df_by_day_4['key4']=df_by_day_4['key4'].astype('int')\n",
    "    df_by_day_4['Dia']=df_by_day_4['Dia'].astype('int')\n",
    "    if (nivel_4==\"cd_geocmi\"):\n",
    "        df_by_day_4=df_by_day_4.rename(columns={nivel_4:'adm4'})\n",
    "    #if (dia=='1' and mes=='2'):\n",
    "    #    df_final_4=df_by_day_4\n",
    "    #else:\n",
    "    #    df_final_4=df_final_4.append(df_by_day_4)\n",
    "        \n",
    "    table_uc = f'historico_latlong_{pais}_{codigo_fecha}_nivel4'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_4,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_niveles/Temp_BR/{table_uc}\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ##Filtro severo\n",
    "    #nivel 1\n",
    "    df2=df.merge(df_filtro,how='inner',on='caid')    \n",
    "    df_by_day_11=df2.groupby(['month','day',nivel_1]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_11=df_by_day_11.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_11['%MasDe1km'] = df_by_day_11['MasDe1km']/df_by_day_11['n_users']*100  \n",
    "    df_median=df2[df2['MasDe1km']==1].groupby(['month','day',nivel_1]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_11=df_by_day_11.merge(df_median, how='left',on=['Mes','Dia',nivel_1])      \n",
    "    df_by_day_11[nivel_1]=df_by_day_11[nivel_1].astype('int')\n",
    "    df_by_day_11['Mes']=df_by_day_11['Mes'].astype('int')\n",
    "    df_by_day_11['Dia']=df_by_day_11['Dia'].astype('int')\n",
    "    df_by_day_11[\"Dia\"]=df_by_day_11[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_11[\"key4\"]=df_by_day_11['Mes'].astype(str)+ df_by_day_11[\"Dia\"].astype(str)\n",
    "    df_by_day_11['key4']=df_by_day_11['key4'].astype('int')\n",
    "    df_by_day_11['Dia']=df_by_day_11['Dia'].astype('int')    \n",
    "    if (nivel_1==\"id_provincia\"):\n",
    "        df_by_day_11=df_by_day_11.rename(columns={nivel_1:'adm1'})\n",
    "    #if (dia=='1' and mes=='2'):\n",
    "    #    df_final_fs1=df_by_day_11\n",
    "    #else:\n",
    "    #    df_final_fs1=df_final_fs1.append(df_by_day_11)\n",
    "    \n",
    "    table_uc = f'historico_latlong_{pais}_{codigo_fecha}_nivel1_fs'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_11,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_niveles/Temp_BR/{table_uc}\"\n",
    "    ) \n",
    "    \n",
    "    \n",
    "    #nivel 4\n",
    "    df2=df.merge(df_filtro,how='inner',on='caid')\n",
    "    df_by_day_44=df2.groupby(['month','day',nivel_4]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_44=df_by_day_44.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_44['%MasDe1km'] = df_by_day_44['MasDe1km']/df_by_day_44['n_users']*100  \n",
    "    df_median=df2[df2['MasDe1km']==1].groupby(['month','day',nivel_4]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_44=df_by_day_44.merge(df_median, how='left',on=['Mes','Dia',nivel_4])      \n",
    "    df_by_day_44[nivel_4]=df_by_day_44[nivel_4].astype('int')\n",
    "    df_by_day_44['Mes']=df_by_day_44['Mes'].astype('int')\n",
    "    df_by_day_44['Dia']=df_by_day_44['Dia'].astype('int')\n",
    "    df_by_day_44[\"Dia\"]=df_by_day_44[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_44[\"key4\"]=df_by_day_44['Mes'].astype(str)+ df_by_day_44[\"Dia\"].astype(str)\n",
    "    df_by_day_44['key4']=df_by_day_44['key4'].astype('int')\n",
    "    df_by_day_44['Dia']=df_by_day_44['Dia'].astype('int')\n",
    "    if (nivel_4==\"cd_geocmi\"):\n",
    "        df_by_day_44=df_by_day_44.rename(columns={nivel_4:'adm4'})\n",
    "    #if (dia=='1' and mes=='2'):\n",
    "    #    df_final_fs4=df_by_day_44\n",
    "    #else:\n",
    "    #    df_final_fs4=df_final_fs4.append(df_by_day_44)\n",
    "        \n",
    "    table_uc = f'historico_latlong_{pais}_{codigo_fecha}_nivel4_fs'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_44,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_niveles/Temp_BR/{table_uc}\"\n",
    "    )  \n",
    "    \n",
    "\n",
    "    tiempo = (time.time()-time_fecha)\n",
    "    print(f\"{mes}{dia}, {int(tiempo)} seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control - Filtro 10p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_region=pd.read_excel('cod_BR.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo adm1 de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212061564127604\n"
     ]
    }
   ],
   "source": [
    "df_final = []\n",
    "start_time = time.time()\n",
    "for i,fecha in enumerate(fechas):\n",
    "    time_fecha = time.time()\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    #print(codigo_fecha)\n",
    "    tabla_usuarios_fecha = f'historico_latlong_{pais}_{codigo_fecha}_nivel1'\n",
    "    query = f'''SELECT * FROM {tabla_usuarios_fecha}'''\n",
    "    #print(f\"{codigo_fecha}\")\n",
    "    df2 = cursor.execute(query).as_pandas()\n",
    "    if (codigo_fecha=='901'):\n",
    "        df_final=df2\n",
    "    else:\n",
    "        df_final=df_final.append(df2)\n",
    "\n",
    "df_final_1 = df_final\n",
    "tiempo = (time.time()-time_fecha)/60\n",
    "print((time.time()-start_time)/60)\n",
    "df_final_1=df_final_1.rename(columns={'mas_de1km':'MasDe1km','_mas_de1km':'%MasDe1km','mediana1_km':'Mediana1KM','mes':'Mes','dia':'Dia'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mes', 'Dia', 'adm1', 'MasDe1km', 'n_users', '%MasDe1km', 'Mediana1KM',\n",
       "       'key4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### control nivel adm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0488025347391765\n"
     ]
    }
   ],
   "source": [
    "df_final = []\n",
    "start_time = time.time()\n",
    "for i,fecha in enumerate(fechas):\n",
    "    time_fecha = time.time()\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    #print(codigo_fecha)\n",
    "    tabla_usuarios_fecha = f'historico_latlong_{pais}_{codigo_fecha}_nivel4'\n",
    "    query = f'''SELECT * FROM {tabla_usuarios_fecha}'''\n",
    "    #print(f\"{codigo_fecha}\")\n",
    "    df2 = cursor.execute(query).as_pandas()\n",
    "    if (codigo_fecha=='901'):\n",
    "        df_final=df2\n",
    "    else:\n",
    "        df_final=df_final.append(df2)\n",
    "df_final=df_final.rename(columns={'mas_de1km':'MasDe1km','_mas_de1km':'%MasDe1km','mediana1_km':'Mediana1KM','mes':'Mes','dia':'Dia'})\n",
    "df_final_4 = df_final\n",
    "tiempo = (time.time()-time_fecha)/60\n",
    "print((time.time()-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990722672833461 CONTINUE\n"
     ]
    }
   ],
   "source": [
    "## control nivel adm4\n",
    "base_control=df_final_1\n",
    "base_control_v4=df_final_4\n",
    "base_control_v4[\"adm1\"]=\"\"\n",
    "base_control_v4.loc[base_control_v4[\"adm4\"].astype(str).str.len()==7,[\"adm1\"]]=base_control_v4[\"adm4\"][base_control_v4[\"adm4\"].astype(str).str.len()==7].map(lambda x: str(x)[0:2])\n",
    "base_control4=base_control_v4.groupby(['Mes','Dia','adm1']).agg({'MasDe1km':'sum','n_users':'sum','%MasDe1km':'mean','Mediana1KM':'median'}).reset_index()\n",
    "base_control4['adm1']=base_control4['adm1'].astype('int')\n",
    "base_control4['adm1_v1']=\"\"\n",
    "\n",
    "for ids in list(cod_region['id_ibge'].astype('int')):\n",
    "    base_control4.loc[base_control4['adm1']== ids , ['adm1_v1']] =  int(cod_region.loc[cod_region['id_ibge']== ids, 'id_provincia'])\n",
    "\n",
    "base_control4 =base_control4.loc[:,['Mes','Dia','adm1_v1','MasDe1km','n_users','%MasDe1km','Mediana1KM']]\n",
    "base_control4 =base_control4.rename(columns={'adm1_v1':'adm1','MasDe1km':'MasDe1km_adm4','n_users':'n_users_adm4','%MasDe1km':'%MasDe1km_adm4','Mediana1KM':'Mediana1KM_adm4'})\n",
    "\n",
    "base_contro4=base_control.merge(base_control4,how='left',on=['Mes','Dia','adm1'])\n",
    "base_contro4['%MasDe1km_adm4']=base_contro4['MasDe1km_adm4']/base_contro4['n_users_adm4']*100\n",
    "\n",
    "cora=base_contro4.groupby('adm1')[['MasDe1km','MasDe1km_adm4']].corr().unstack().iloc[:,1].min()\n",
    "corb=base_contro4.groupby('adm1')[['n_users','n_users_adm4']].corr().unstack().iloc[:,1].min()\n",
    "corc=base_contro4.groupby('adm1')[['%MasDe1km','%MasDe1km_adm4']].corr().unstack().iloc[:,1].min()\n",
    "\n",
    "if (min(cora,corb,corc)<0.9): print(\"OJO\") \n",
    "else: print(min(cora,corb,corc), \"CONTINUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 166546 records to graphdata-mobility-public/Results_niveles/BR/almenos10p/BR_amd4_10p1.csv\n",
      "S3\n",
      "(166546, 9)\n"
     ]
    }
   ],
   "source": [
    "nivel_4 = 'amd4'\n",
    "ruta=f'graphdata-mobility-public/Results_niveles/{pais}/almenos10p/{pais}_{nivel_4}_10p1.csv'\n",
    "write_dataframe_to_csv_on_s3(df_final_4, 'iadbprod-csd-hub-analyticaldata', ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro Base Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8741984248161316\n"
     ]
    }
   ],
   "source": [
    "df_final = []\n",
    "start_time = time.time()\n",
    "for i,fecha in enumerate(fechas):\n",
    "    time_fecha = time.time()\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    #print(codigo_fecha)\n",
    "    tabla_usuarios_fecha = f'historico_latlong_{pais}_{codigo_fecha}_nivel1_fs'\n",
    "    query = f'''SELECT * FROM {tabla_usuarios_fecha}'''\n",
    "    #print(f\"{codigo_fecha}\")\n",
    "    df2 = cursor.execute(query).as_pandas()\n",
    "    if (codigo_fecha=='901'):\n",
    "        df_final=df2\n",
    "    else:\n",
    "        df_final=df_final.append(df2)\n",
    "df_final=df_final.rename(columns={'mas_de1km':'MasDe1km','_mas_de1km':'%MasDe1km','mediana1_km':'Mediana1KM','mes':'Mes','dia':'Dia'})\n",
    "df_final_fs1 = df_final\n",
    "tiempo = (time.time()-time_fecha)/60\n",
    "print((time.time()-start_time)/60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control adm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "1.0129176020622253\n"
     ]
    }
   ],
   "source": [
    "df_final = []\n",
    "start_time = time.time()\n",
    "for i,fecha in enumerate(fechas):\n",
    "    time_fecha = time.time()\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    #print(codigo_fecha)\n",
    "    tabla_usuarios_fecha = f'historico_latlong_{pais}_{codigo_fecha}_nivel4_fs'\n",
    "    query = f'''SELECT * FROM {tabla_usuarios_fecha}'''\n",
    "    print(f\"{codigo_fecha}\")\n",
    "    df2 = cursor.execute(query).as_pandas()\n",
    "    if (codigo_fecha=='901'):\n",
    "        df_final=df2\n",
    "    else:\n",
    "        df_final=df_final.append(df2)\n",
    "df_final=df_final.rename(columns={'mas_de1km':'MasDe1km','_mas_de1km':'%MasDe1km','mediana1_km':'Mediana1KM','mes':'Mes','dia':'Dia'})\n",
    "df_final_fs4 = df_final\n",
    "tiempo = (time.time()-time_fecha)/60\n",
    "print((time.time()-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993257450939125 CONTINUE\n"
     ]
    }
   ],
   "source": [
    "## control nivel adm4\n",
    "base_control=df_final_fs1\n",
    "base_control_v4=df_final_fs4\n",
    "base_control_v4[\"adm1\"]=\"\"\n",
    "base_control_v4.loc[base_control_v4[\"adm4\"].astype(str).str.len()==7,[\"adm1\"]]=base_control_v4[\"adm4\"][base_control_v4[\"adm4\"].astype(str).str.len()==7].map(lambda x: str(x)[0:2])\n",
    "base_control4=base_control_v4.groupby(['Mes','Dia','adm1']).agg({'MasDe1km':'sum','n_users':'sum','%MasDe1km':'mean','Mediana1KM':'median'}).reset_index()\n",
    "base_control4['adm1']=base_control4['adm1'].astype('int')\n",
    "base_control4['adm1_v1']=\"\"\n",
    "\n",
    "for ids in list(cod_region['id_ibge'].astype('int')):\n",
    "    base_control4.loc[base_control4['adm1']== ids , ['adm1_v1']] =  int(cod_region.loc[cod_region['id_ibge']== ids, 'id_provincia'])\n",
    "\n",
    "base_control4 =base_control4.loc[:,['Mes','Dia','adm1_v1','MasDe1km','n_users','%MasDe1km','Mediana1KM']]\n",
    "base_control4 =base_control4.rename(columns={'adm1_v1':'adm1','MasDe1km':'MasDe1km_adm4','n_users':'n_users_adm4','%MasDe1km':'%MasDe1km_adm4','Mediana1KM':'Mediana1KM_adm4'})\n",
    "\n",
    "base_contro4=base_control.merge(base_control4,how='left',on=['Mes','Dia','adm1'])\n",
    "base_contro4['%MasDe1km_adm4']=base_contro4['MasDe1km_adm4']/base_contro4['n_users_adm4']*100\n",
    "\n",
    "cora=base_contro4.groupby('adm1')[['MasDe1km','MasDe1km_adm4']].corr().unstack().iloc[:,1].min()\n",
    "corb=base_contro4.groupby('adm1')[['n_users','n_users_adm4']].corr().unstack().iloc[:,1].min()\n",
    "corc=base_contro4.groupby('adm1')[['%MasDe1km','%MasDe1km_adm4']].corr().unstack().iloc[:,1].min()\n",
    "\n",
    "if (min(cora,corb,corc)<0.9): print(\"OJO\") \n",
    "else: print(min(cora,corb,corc), \"CONTINUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 158824 records to graphdata-mobility-public/Results_niveles/BR/base_usuario/BR_cd_geocmi_baseuser1.csv\n",
      "S3\n",
      "(158824, 9)\n"
     ]
    }
   ],
   "source": [
    "nivel_4 = 'cd_geocmi'\n",
    "ruta=f'graphdata-mobility-public/Results_niveles/{pais}/base_usuario/{pais}_{nivel_4}_baseuser1.csv'\n",
    "write_dataframe_to_csv_on_s3(df_final_fs4, 'iadbprod-csd-hub-analyticaldata', ruta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
