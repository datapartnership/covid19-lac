{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/enum.py\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "print(enum.__file__)  \n",
    "# standard library location should be something like \n",
    "# /usr/local/lib/python3.6/enum.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping enum34 as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip uninstall -y enum34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: boto3<2.1.0,>=1.16.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.17.99)\n",
      "Requirement already satisfied: botocore<2.1.0,>=1.19.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.20.99)\n",
      "Requirement already satisfied: pg8000<1.21.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.20.0)\n",
      "Requirement already satisfied: pymysql<1.1.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.0.2)\n",
      "Requirement already satisfied: redshift-connector~=2.0.882 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (2.0.883)\n",
      "Requirement already satisfied: pyarrow<4.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (4.0.1)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: pandas<2.1.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (1.1.5)\n",
      "Requirement already satisfied: openpyxl~=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from awswrangler) (3.0.6)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.1.0,>=1.16.8->awswrangler) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2.1.0,>=1.16.8->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.1.0,>=1.19.8->awswrangler) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<2.1.0,>=1.19.8->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openpyxl~=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<2.1.0,>=1.1.0->awswrangler) (2021.1)\n",
      "Requirement already satisfied: scramp>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pg8000<1.21.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.1.0,>=1.19.8->awswrangler) (1.15.0)\n",
      "Requirement already satisfied: requests<2.25.2,>=2.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.882->awswrangler) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.882->awswrangler) (4.9.3)\n",
      "Requirement already satisfied: lxml>=4.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from redshift-connector~=2.0.882->awswrangler) (4.6.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector~=2.0.882->awswrangler) (2.0.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.882->awswrangler) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.882->awswrangler) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.25.2,>=2.23.0->redshift-connector~=2.0.882->awswrangler) (2021.5.30)\n",
      "Requirement already satisfied: asn1crypto==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scramp>=1.4.0->pg8000<1.21.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAthena in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (8.0.1)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.17.99)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.20.99)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.4.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.5.52->PyAthena) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install PyAthena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectar con pyathena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena.pandas.cursor import PandasCursor\n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "import time\n",
    "# agregar directorio en el cual se almacenan las tablas que se van a consultar\n",
    "directorio = 's3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/athena-results/'\n",
    "# base de datos\n",
    "bd = 'graphdata' # Database in Glue\n",
    "cursor = connect(s3_staging_dir = directorio, region_name = 'us-east-1', schema_name = bd, cursor_class = PandasCursor).cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "import calendar\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaraci√≥n funciones para Impo-Expo s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_csv_on_s3(dataframe, bucket, filename):\n",
    "    \"\"\" Write a dataframe to a CSV on S3 \"\"\"\n",
    "    # Create buffer\n",
    "    csv_buffer = StringIO()\n",
    "    # Write dataframe to buffer\n",
    "    dataframe.to_csv(csv_buffer, sep=\";\" , line_terminator='\\n')\n",
    "    # Create S3 object\n",
    "    s3_resource = boto3.resource(\"s3\")\n",
    "    # Write buffer to S3 object\n",
    "    s3_resource.Object(bucket, filename).put(Body=csv_buffer.getvalue())\n",
    "    print(\"Writing {} records to {}\".format(len(dataframe), filename))\n",
    "    print(\"S3\")\n",
    "    print(dataframe.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_excel_on_s3(dataframe, bucket, filename):\n",
    "    \"\"\" Write a dataframe to a excel on S3 \"\"\"\n",
    "    with io.BytesIO() as output:\n",
    "        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "            dataframe.to_excel(writer,index=False)\n",
    "        data = output.getvalue()\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).put_object(Key=filename, Body=data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe_csv_from_s3(bucket, filename):\n",
    "    client = boto3.client('s3')\n",
    "    bucket_name = bucket\n",
    "    object_key = filename\n",
    "    csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string),sep=\";\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe_excel_from_s3(bucket, filename):\n",
    "    client = boto3.client('s3')\n",
    "    bucket_name = bucket\n",
    "    object_key = filename\n",
    "    obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    data = obj['Body'].read()\n",
    "    df = pd.read_excel(io.BytesIO(data), encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_to_s3(bucket,file_local,file_s3):\n",
    "    s3.Bucket(bucket).upload_file(file_local,file_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea tabla de indicadores por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_inicio = '09-01-2020'\n",
    "fecha_final = '09-30-2020'\n",
    "fechas = pd.date_range(fecha_inicio, fecha_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pais = 'LATAM'\n",
    "nivel_4 = 'id_city'\n",
    "#id_city = 'id_city'\n",
    "name_city = 'name_city'\n",
    "country_city = 'country_city'\n",
    "filtro_variable = \"n_obs\"\n",
    "filtro_num = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computar serie de usuarios homogenea\n",
    "filtro_variable2 = 'n_obs_madrugada'\n",
    "filtro_variable22 = 'n_obs_noche'\n",
    "filtro_num2 = 4\n",
    "#consulta athena\n",
    "tabla_usuarios_distancia =  f'historico_usuarios_cities_{pais}'   \n",
    "query_filtro = (f''' SELECT caid,\n",
    "                            count(*) as count_filtro\n",
    "                     FROM {tabla_usuarios_distancia} \n",
    "                     WHERE (({tabla_usuarios_distancia}.{filtro_variable2} + {tabla_usuarios_distancia}.{filtro_variable22})>= {filtro_num2})\n",
    "                     GROUP BY caid\n",
    "                     HAVING count(*)>=30''')\n",
    "df_filtro = cursor.execute(query_filtro).as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91, 71 seg\n",
      "92, 64 seg\n",
      "93, 63 seg\n",
      "94, 65 seg\n",
      "95, 61 seg\n",
      "96, 57 seg\n",
      "97, 56 seg\n",
      "98, 59 seg\n",
      "99, 61 seg\n",
      "910, 57 seg\n",
      "911, 56 seg\n",
      "912, 52 seg\n",
      "913, 38 seg\n",
      "914, 43 seg\n",
      "915, 36 seg\n",
      "916, 31 seg\n",
      "917, 29 seg\n",
      "918, 25 seg\n",
      "919, 25 seg\n",
      "920, 28 seg\n",
      "921, 50 seg\n",
      "922, 61 seg\n",
      "923, 58 seg\n",
      "924, 62 seg\n",
      "925, 58 seg\n",
      "926, 57 seg\n",
      "927, 58 seg\n",
      "928, 58 seg\n",
      "929, 61 seg\n",
      "930, 49 seg\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for fecha in fechas:\n",
    "    time_fecha = time.time()\n",
    "    dia = str(fecha.day)\n",
    "    mes = str(fecha.month)\n",
    "    query_fecha = \"\"\n",
    "    day = str(fecha.day)\n",
    "    if len(day) == 1:\n",
    "        day = f'0{day}'\n",
    "    codigo_fecha = str(fecha.month) + day\n",
    "    tabla_usuarios_distancia =  f'historico_usuarios_cities_{pais}'   \n",
    "    query_filtro = (f''' SELECT *\n",
    "                         FROM {tabla_usuarios_distancia} \n",
    "                         WHERE ({tabla_usuarios_distancia}.month={mes}\n",
    "                         AND {tabla_usuarios_distancia}.day={dia} \n",
    "                         AND {tabla_usuarios_distancia}.{filtro_variable} >= {filtro_num})''')\n",
    "    df = cursor.execute(query_filtro).as_pandas()\n",
    "    df['MasDe1km'] = df['distancia_recorrida'].apply(lambda x: 1 if x>=1 else 0)\n",
    "    \n",
    "    \n",
    "    ##Filtro mas tenue\n",
    "    \n",
    "    #Cities  \n",
    "    df_by_day_4=df.groupby(['month','day', nivel_4, name_city, country_city]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_4=df_by_day_4.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_4['%MasDe1km'] = df_by_day_4['MasDe1km']/df_by_day_4['n_users']*100  \n",
    "    df_median=df[df['MasDe1km']==1].groupby(['month','day',nivel_4]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_4=df_by_day_4.merge(df_median, how='left',on=['Mes','Dia',nivel_4])    \n",
    "    df_by_day_4[nivel_4]=df_by_day_4[nivel_4].astype('int')\n",
    "    df_by_day_4['Mes']=df_by_day_4['Mes'].astype('int')\n",
    "    df_by_day_4['Dia']=df_by_day_4['Dia'].astype('int')\n",
    "    df_by_day_4[\"Dia\"]=df_by_day_4[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_4[\"key4\"]=df_by_day_4['Mes'].astype(str)+ df_by_day_4[\"Dia\"].astype(str)\n",
    "    df_by_day_4['key4']=df_by_day_4['key4'].astype('int')\n",
    "    df_by_day_4['Dia']=df_by_day_4['Dia'].astype('int')\n",
    "        \n",
    "    table_uc = f'historico_cities_{pais}_{codigo_fecha}'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_4,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_cities/Temp_{pais}/{table_uc}\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ##Filtro severo\n",
    "\n",
    "    #Cities\n",
    "    df2=df.merge(df_filtro,how='inner',on='caid')\n",
    "    df_by_day_44=df2.groupby(['month','day',nivel_4, name_city, country_city]).agg({'MasDe1km':'sum','caid':'count'}).reset_index()\n",
    "    df_by_day_44=df_by_day_44.rename(columns={'caid':'n_users','month':'Mes','day':'Dia'})\n",
    "    df_by_day_44['%MasDe1km'] = df_by_day_44['MasDe1km']/df_by_day_44['n_users']*100  \n",
    "    df_median=df2[df2['MasDe1km']==1].groupby(['month','day',nivel_4]).agg({'distancia_recorrida':'median'}).reset_index()\n",
    "    df_median=df_median.rename(columns={'distancia_recorrida':'Mediana1KM','month':'Mes','day':'Dia'})\n",
    "    df_by_day_44=df_by_day_44.merge(df_median, how='left',on=['Mes','Dia',nivel_4])      \n",
    "    df_by_day_44[nivel_4]=df_by_day_44[nivel_4].astype('int')\n",
    "    df_by_day_44['Mes']=df_by_day_44['Mes'].astype('int')\n",
    "    df_by_day_44['Dia']=df_by_day_44['Dia'].astype('int')\n",
    "    df_by_day_44[\"Dia\"]=df_by_day_44[\"Dia\"].map(\"{:02}\".format)\n",
    "    df_by_day_44[\"key4\"]=df_by_day_44['Mes'].astype(str)+ df_by_day_44[\"Dia\"].astype(str)\n",
    "    df_by_day_44['key4']=df_by_day_44['key4'].astype('int')\n",
    "    df_by_day_44['Dia']=df_by_day_44['Dia'].astype('int')\n",
    "        \n",
    "    table_uc = f'historico_cities_{pais}_{codigo_fecha}_fs'\n",
    "    wr.s3.to_parquet(  # Storing the data and metadata to Data Lake\n",
    "    df = df_by_day_44,\n",
    "    dataset = True,\n",
    "    table = table_uc,\n",
    "    database = \"graphdata\",\n",
    "    path = f\"s3://iadbprod-csd-hub-analyticaldata/graphdata-mobility-temporal/Results_cities/Temp_{pais}/{table_uc}\"\n",
    "    )  \n",
    "    \n",
    "\n",
    "    tiempo = (time.time()-time_fecha)\n",
    "    print(f\"{mes}{dia}, {int(tiempo)} seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminacion de tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pais = 'LATAM'\n",
    "try:\n",
    "    fecha_inicio = '02-01-2020'\n",
    "    fecha_final = '02-01-2020'\n",
    "    fechas = pd.date_range(fecha_inicio, fecha_final)\n",
    "    for fecha in fechas:\n",
    "        day = str(fecha.day)\n",
    "        if len(day) == 1:\n",
    "            day = f'0{day}'\n",
    "        codigo_fecha = str(fecha.month) + day\n",
    "        print(codigo_fecha)\n",
    "        \n",
    "        tabla_datos_pais = f\"historico_cities_{pais}_{codigo_fecha}\"\n",
    "        query = f\"DROP TABLE {tabla_datos_pais}\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        tabla_datos_pais = f\"historico_cities_{pais}_{codigo_fecha}_fs\"\n",
    "        query = f\"DROP TABLE {tabla_datos_pais}\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "except:\n",
    "    print(f\" Eliminado \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
